{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 # variable for denoting rank\n",
    "rank = [] # list for storing rank\n",
    "review = [] # list for storing review\n",
    "num_images = [] # list for storing number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: DeprecationWarning: MyOpener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
      "C:\\Users\\iamak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: DeprecationWarning: MyOpener style of invoking requests is deprecated. Use newer urlopen functions/methods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from urllib.request import FancyURLopener  # This is library that helps us create the headless browser\n",
    "import random\n",
    "from random import choice #This library helps pick a random item from a list\n",
    "import bs4 as bs\n",
    "\n",
    "# create user agents\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "]\n",
    "\n",
    "# read csv file\n",
    "df = pd.read_csv(\"electronics.csv\", encoding = 'latin1')\n",
    "\n",
    "# create product links\n",
    "link = []\n",
    "for i in df['product_link']:\n",
    "#     index = i.find(\"ref=\")\n",
    "#     i = i[:index]\n",
    "    link.append(\"https://www.amazon.com\" + i)\n",
    "\n",
    "# create review page link\n",
    "rating = []\n",
    "for i in df['rating_link']:\n",
    "#     index = i.find(\"ref=\")\n",
    "#     i = i[:index]\n",
    "    rating.append(\"https://www.amazon.com\" + i)    \n",
    "\n",
    "# define class for fancy url opener\n",
    "class MyOpener(FancyURLopener, object):\n",
    "    version = choice(user_agents)\n",
    "\n",
    "# a = 1 # variable for denoting rank\n",
    "# rank = [] # list for storing rank\n",
    "# review = [] # list for storing review\n",
    "# num_images = [] # list for storing number of images\n",
    "\n",
    "for i in link: # iterate over all product links\n",
    "    try:\n",
    "        myopener = MyOpener()\n",
    "        page=myopener.open(i) # open page using fancy url\n",
    "        time.sleep(random.uniform(1, 3))  #sleep time \n",
    "\n",
    "        html = page.read().decode('utf-8') # generate html for the page\n",
    "        soup = bs.BeautifulSoup(html) # create bs obejct for html source code\n",
    "\n",
    "        # get number of images\n",
    "        infotable = soup.find_all(\"li\", class_ = \"a-spacing-small item\")\n",
    "        num_images.append(len(infotable)) # will have length 100 for 100 products\n",
    "\n",
    "        # get link for review page\n",
    "        url = [] # list to capture link for review page\n",
    "        infotable = soup.find_all(\"a\", class_ = \"a-link-emphasis a-text-bold\")\n",
    "        if infotable: # if link for review page is found\n",
    "            for link in infotable:\n",
    "                url.append(\"https://www.amazon.com\" + link.get('href')) #create url for the review page\n",
    "            try:\n",
    "                # run the below code if review page opens\n",
    "                myopener = MyOpener()\n",
    "                page=myopener.open(url[0]) # open review page\n",
    "                time.sleep(random.uniform(0,2))  #sleep time \n",
    "                html = page.read().decode('utf-8')\n",
    "                soup = bs.BeautifulSoup(html)\n",
    "\n",
    "                # get top 10 reviews\n",
    "                infotable = soup.find_all(\"div\", class_ = \"a-row a-spacing-small review-data\")\n",
    "                for link in infotable:\n",
    "                    review.append(link.getText()) # append each review\n",
    "                    rank.append(a) #append rank for each review\n",
    "            except:\n",
    "                # run if review page does not open\n",
    "                rank.append(a)\n",
    "                review.append(\"no review\")\n",
    "        else: # if link for review page is not found\n",
    "            rank.append(a)\n",
    "            review.append(\"no review\")\n",
    "        print(a)\n",
    "        a = a+1 # go to next rank\n",
    "    except:\n",
    "        a = a+1\n",
    "        rank.append(a)\n",
    "        review.append(\"no review\")\n",
    "        num_images.append(\"no image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the scraped data  - rank and review to csv file\n",
    "import csv\n",
    "with open('electronics_reviews.csv', mode='w', encoding=\"utf-8-sig\") as output_file:\n",
    "    output_writer = csv.writer(output_file, delimiter=',', lineterminator='\\n')\n",
    "    output_writer.writerow(['rank', 'review'])\n",
    "    for x in range(0, len(rank)):\n",
    "        myData = [rank[x], review[x]]\n",
    "        output_writer.writerow(myData)\n",
    "\n",
    "# write number of images to csv file\n",
    "data = pd.DataFrame()\n",
    "data['num_images'] = num_images\n",
    "data.to_csv('electronics_images.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
